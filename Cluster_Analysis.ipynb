{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import praw\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from helpers import connect, close, table_to_df\n",
    "import config\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets\n",
    "\n",
    "The first step is to load the datasets from the database. I used sqlite3, an embedded database management system, to store my data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, c = connect(config.database)\n",
    "\n",
    "### load the POSTS table into dataframe\n",
    "posts = table_to_df(conn, 'POSTS')\n",
    "\n",
    "### load the COMMENTS table into dataframe\n",
    "comments_raw = table_to_df(conn, 'COMMENTS')\n",
    "\n",
    "# convert the COMMENTS to list of strings\n",
    "comments_raw['COMMENTS'] = comments_raw['COMMENTS'].map(lambda x: ast.literal_eval(x))\n",
    "\n",
    "### Transform each element of a list-like to a row, replicating index values\n",
    "comments = comments_raw.explode('COMMENTS')\n",
    "\n",
    "close(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to check if there are any NAs in the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "title           0\n",
       "score           0\n",
       "subreddit       0\n",
       "num_comments    0\n",
       "body            0\n",
       "created         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID          0\n",
       "COMMENTS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(954, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, let us take a look at the **POSTS** table, which includes the megadata for each post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6bo3mk</td>\n",
       "      <td>xkcd: Machine Learning</td>\n",
       "      <td>376</td>\n",
       "      <td>datascience</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td>2017-05-17 15:33:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6gi8lw</td>\n",
       "      <td>I need to print this out and put it on my cube.</td>\n",
       "      <td>367</td>\n",
       "      <td>datascience</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>2017-06-11 03:11:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>713hnw</td>\n",
       "      <td>How I went from no coding or machine learning ...</td>\n",
       "      <td>628</td>\n",
       "      <td>datascience</td>\n",
       "      <td>107</td>\n",
       "      <td>TL;DR: learned a buncha shit in 20 months with...</td>\n",
       "      <td>2017-09-19 18:54:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>75aqpg</td>\n",
       "      <td>Impossible Job Requirements</td>\n",
       "      <td>429</td>\n",
       "      <td>datascience</td>\n",
       "      <td>54</td>\n",
       "      <td></td>\n",
       "      <td>2017-10-09 21:40:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>80rhvh</td>\n",
       "      <td>newbies be like</td>\n",
       "      <td>510</td>\n",
       "      <td>datascience</td>\n",
       "      <td>130</td>\n",
       "      <td></td>\n",
       "      <td>2018-02-28 03:05:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  score  \\\n",
       "133  6bo3mk                             xkcd: Machine Learning    376   \n",
       "135  6gi8lw    I need to print this out and put it on my cube.    367   \n",
       "33   713hnw  How I went from no coding or machine learning ...    628   \n",
       "105  75aqpg                        Impossible Job Requirements    429   \n",
       "68   80rhvh                                    newbies be like    510   \n",
       "\n",
       "       subreddit  num_comments  \\\n",
       "133  datascience            20   \n",
       "135  datascience            10   \n",
       "33   datascience           107   \n",
       "105  datascience            54   \n",
       "68   datascience           130   \n",
       "\n",
       "                                                  body              created  \n",
       "133                                                     2017-05-17 15:33:34  \n",
       "135                                                     2017-06-11 03:11:17  \n",
       "33   TL;DR: learned a buncha shit in 20 months with...  2017-09-19 18:54:11  \n",
       "105                                                     2017-10-09 21:40:47  \n",
       "68                                                      2018-02-28 03:05:06  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the dataset by data created and display the top five rows\n",
    "posts.sort_values(by = ['created'], ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us then take a look at the **COMMENTS** table, which includes the top comments for each post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fzweaf</td>\n",
       "      <td>[This is very useful and makes me want to quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cgwvds</td>\n",
       "      <td>[Oh hey, more awesome stuff I have no time for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aohn8w</td>\n",
       "      <td>[Tools: http://sankeymatic.com/\\n\\nData: Self-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bupmyf</td>\n",
       "      <td>[IMO this is a large part of the reason data s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drde9q</td>\n",
       "      <td>[Honestly, if you understand the most fundamen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                           COMMENTS\n",
       "0  fzweaf  [This is very useful and makes me want to quit...\n",
       "1  cgwvds  [Oh hey, more awesome stuff I have no time for...\n",
       "2  aohn8w  [Tools: http://sankeymatic.com/\\n\\nData: Self-...\n",
       "3  bupmyf  [IMO this is a large part of the reason data s...\n",
       "4  drde9q  [Honestly, if you understand the most fundamen..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using explode, we can transform each element of a list-like to a row, replicating index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fzweaf</td>\n",
       "      <td>This is very useful and makes me want to quit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fzweaf</td>\n",
       "      <td>I would rename this article as my RDBMS Checkl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fzweaf</td>\n",
       "      <td>&gt; CUSTOMER, CUSTOMER_NEW, CUSTOMER_NEW_NEW\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fzweaf</td>\n",
       "      <td>Interesting, what’s your background?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fzweaf</td>\n",
       "      <td>I appreciate very much your kind gift</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                           COMMENTS\n",
       "0  fzweaf  This is very useful and makes me want to quit ...\n",
       "0  fzweaf  I would rename this article as my RDBMS Checkl...\n",
       "0  fzweaf  > CUSTOMER, CUSTOMER_NEW, CUSTOMER_NEW_NEW\\n\\n...\n",
       "0  fzweaf               Interesting, what’s your background?\n",
       "0  fzweaf              I appreciate very much your kind gift"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the length of all the comments, find the distribution of comment lengths and filter the comments by length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['COMMENTS_LENGTH'] = comments['COMMENTS'].str.split().str.len().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the length of the comments is 58.21530180699731.\n",
      "The median of the length of the comments is 29.0.\n",
      "The standard deviation of the length of the comments is 83.13319961716927.\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the length of the comments is {}.'.format(comments['COMMENTS_LENGTH'].mean()))\n",
    "print('The median of the length of the comments is {}.'.format(comments['COMMENTS_LENGTH'].median()))\n",
    "print('The standard deviation of the length of the comments is {}.'.format(comments['COMMENTS_LENGTH'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9571628550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments[comments['COMMENTS_LENGTH'] < 100]['COMMENTS_LENGTH'].hist()\n",
    "\n",
    "### looking at everything below 28, look at different bins; \n",
    "### what seems to be consistent. what sort of scaling would you want to consider? take a look at the terms. power transform/log transform\n",
    "### as the weight? Consider something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259323337178008"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the proportion of comments shorter than 100 words\n",
    "(comments[comments['COMMENTS_LENGTH'] < 100].shape[0])/(len(comments['COMMENTS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17406766628219916"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the proportion of comments longer than 100 words\n",
    "(comments[comments['COMMENTS_LENGTH'] >= 100].shape[0])/(len(comments['COMMENTS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6bo3mk</th>\n",
       "      <td>[This is henceforth going to be a slide in eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6gi8lw</th>\n",
       "      <td>[apology for poor english\\n\\nwhere were you wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713hnw</th>\n",
       "      <td>[You greatly underestimate the value of your m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75aqpg</th>\n",
       "      <td>[What, no PhD requirement to go along with it?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80rhvh</th>\n",
       "      <td>[Seems like this ended up being a good opportu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 COMMENTS\n",
       "ID                                                       \n",
       "6bo3mk  [This is henceforth going to be a slide in eve...\n",
       "6gi8lw  [apology for poor english\\n\\nwhere were you wh...\n",
       "713hnw  [You greatly underestimate the value of your m...\n",
       "75aqpg  [What, no PhD requirement to go along with it?...\n",
       "80rhvh  [Seems like this ended up being a good opportu..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_short = comments.query('COMMENTS_LENGTH >0 & COMMENTS_LENGTH < 100')[['ID', 'COMMENTS']].groupby('ID').agg(lambda x: x.tolist())\n",
    "comments_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>713hnw</th>\n",
       "      <td>[&gt;The name of the school and the operations re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80rhvh</th>\n",
       "      <td>[Man, every time I see a post like this it jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8nl2ps</th>\n",
       "      <td>[Years ago I worked at a headhunter and saw ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9f18t6</th>\n",
       "      <td>[This is why I have no interest in socializing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9lprhw</th>\n",
       "      <td>[I was in a class like this for computer archi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 COMMENTS\n",
       "ID                                                       \n",
       "713hnw  [>The name of the school and the operations re...\n",
       "80rhvh  [Man, every time I see a post like this it jus...\n",
       "8nl2ps  [Years ago I worked at a headhunter and saw ho...\n",
       "9f18t6  [This is why I have no interest in socializing...\n",
       "9lprhw  [I was in a class like this for computer archi..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_long = comments.query('COMMENTS_LENGTH > 100')[['ID', 'COMMENTS']].groupby('ID').agg(lambda x: x.tolist())\n",
    "comments_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import re\n",
    "def preprocessing(df):\n",
    "    ## Join the list of string into one long string:\n",
    "    df['COMMENTS'] = df['COMMENTS'].str.join(' ')\n",
    "\n",
    "    ## Remove empty space:\n",
    "    df['COMMENTS'] = df['COMMENTS'].map(lambda x: re.sub('\\s+', ' ', x))\n",
    "\n",
    "    ## Convert all string to lower cases:\n",
    "    df['COMMENTS'] = df['COMMENTS'].str.lower()\n",
    "\n",
    "    ## Remove all the punctuations:\n",
    "    df['COMMENTS'] = df['COMMENTS'].map(lambda x: re.sub('[^\\w\\s]', '', x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fzweaf</td>\n",
       "      <td>this is very useful and makes me want to quit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cgwvds</td>\n",
       "      <td>oh hey more awesome stuff i have no time for  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aohn8w</td>\n",
       "      <td>tools httpsankeymaticcom data selfgathered dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bupmyf</td>\n",
       "      <td>imo this is a large part of the reason data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drde9q</td>\n",
       "      <td>honestly if you understand the most fundamenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                           COMMENTS\n",
       "0  fzweaf  this is very useful and makes me want to quit ...\n",
       "1  cgwvds  oh hey more awesome stuff i have no time for  ...\n",
       "2  aohn8w  tools httpsankeymaticcom data selfgathered dat...\n",
       "3  bupmyf  imo this is a large part of the reason data sc...\n",
       "4  drde9q  honestly if you understand the most fundamenta..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_raw = preprocessing(comments_raw)\n",
    "comments_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6bo3mk</th>\n",
       "      <td>this is henceforth going to be a slide in ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6gi8lw</th>\n",
       "      <td>apology for poor english where were you when c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713hnw</th>\n",
       "      <td>you greatly underestimate the value of your ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75aqpg</th>\n",
       "      <td>what no phd requirement to go along with it de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80rhvh</th>\n",
       "      <td>seems like this ended up being a good opportun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 COMMENTS\n",
       "ID                                                       \n",
       "6bo3mk  this is henceforth going to be a slide in ever...\n",
       "6gi8lw  apology for poor english where were you when c...\n",
       "713hnw  you greatly underestimate the value of your ma...\n",
       "75aqpg  what no phd requirement to go along with it de...\n",
       "80rhvh  seems like this ended up being a good opportun..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_short = preprocessing(comments_short)\n",
    "comments_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>713hnw</th>\n",
       "      <td>the name of the school and the operations rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80rhvh</th>\n",
       "      <td>man every time i see a post like this it just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8nl2ps</th>\n",
       "      <td>years ago i worked at a headhunter and saw how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9f18t6</th>\n",
       "      <td>this is why i have no interest in socializing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9lprhw</th>\n",
       "      <td>i was in a class like this for computer archit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 COMMENTS\n",
       "ID                                                       \n",
       "713hnw  the name of the school and the operations rese...\n",
       "80rhvh  man every time i see a post like this it just ...\n",
       "8nl2ps  years ago i worked at a headhunter and saw how...\n",
       "9f18t6  this is why i have no interest in socializing ...\n",
       "9lprhw  i was in a class like this for computer archit..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_long = preprocessing(comments_long)\n",
    "comments_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the stemmer, tokenizer and the stop_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop_words = stopwords.words('english')\n",
    "\n",
    "more_stop_words = ['could', 'really', 'would','one','also','days', \n",
    "                  'say', 'can', 'id', 'ive', 'arent', 'something', 'many', 'etc', 'even', \n",
    "                   'like', 'just', 'im', 'dont', 'youre', 'great', 'nice', 'good', 'data', 'thank', 'lol']\n",
    "\n",
    "stop_words = nltk_stop_words + more_stop_words\n",
    "\n",
    "# define the Stemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "stop_words = [stemmer.stem(word) for word in stop_words]\n",
    "\n",
    "# define the Tokenizer\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z\\']+')\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    return [stemmer.stem(word) for word in tokenizer.tokenize(text)]\n",
    "\n",
    "def tokenize_only(text):\n",
    "    return tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms_short = comments_short['COMMENTS'].values\n",
    "\n",
    "comms_long = comments_long['COMMENTS'].values\n",
    "\n",
    "comms = comments_raw['COMMENTS'].values\n",
    "\n",
    "# # tokenize only, no stemmize\n",
    "# # max_features = 500: only consider the top max_features ordered by term frequency\n",
    "# vectorizer1 = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize_only, max_features = 200)\n",
    "# X1 = vectorizer1.fit_transform(comms)\n",
    "# X1_norm = normalize(X1)\n",
    "# words1 = vectorizer1.get_feature_names()\n",
    "\n",
    "# tokenize and stemmize\n",
    "# max_features = 500: only consider the top max_features ordered by term frequency\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize_and_stem, max_features = 200)\n",
    "X_short = vectorizer.fit_transform(comms_short)\n",
    "X_short_norm = normalize(X_short)\n",
    "words_short = vectorizer.get_feature_names()\n",
    "### try the raw count to compare with tfidf. \n",
    "\n",
    "### try to get some non-NLP, more statistical test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize_and_stem, max_features = 200)\n",
    "X_long = vectorizer.fit_transform(comms_long)\n",
    "X_long_norm = normalize(X_long)\n",
    "words_long = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize_and_stem, max_features = 200)\n",
    "X = vectorizer.fit_transform(comms)\n",
    "X_norm = normalize(X)\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : get, look, work, want, need, go, make, cours, know, project, think\n",
      "1 : interview, job, get, role, compani, ds, scienc, ask, posit, work, question\n",
      "2 : scienc, work, learn, scientist, job, get, know, peopl, engin, time, compani\n",
      "3 : use, model, work, featur, predict, need, tri, notebook, make, get, look\n",
      "4 : r, python, use, languag, sas, code, learn, work, sql, panda, need\n"
     ]
    }
   ],
   "source": [
    "# for X_short\n",
    "kmeans_5 = KMeans(n_clusters = 5, n_init = 5, n_jobs = -1)\n",
    "kmeans_5.fit(X_short)\n",
    "\n",
    "common_words = kmeans_5.cluster_centers_.argsort()[:,-1:-12:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words_short[word] for word in centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : r, python, use, languag, learn, tool, sql, know, excel, work, peopl\n",
      "1 : use, get, work, peopl, make, time, code, need, project, thing, want\n",
      "2 : model, use, featur, predict, train, learn, problem, need, custom, work, time\n",
      "3 : scienc, job, program, learn, work, get, math, degre, scientist, year, cours\n",
      "4 : compani, work, job, get, team, manag, peopl, scientist, ds, scienc, time\n"
     ]
    }
   ],
   "source": [
    "# for X_long\n",
    "kmeans_5 = KMeans(n_clusters = 5, n_init = 5, n_jobs = -1)\n",
    "kmeans_5.fit(X_long)\n",
    "\n",
    "common_words = kmeans_5.cluster_centers_.argsort()[:,-1:-12:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words_long[word] for word in centroid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Number of Clusters\n",
    "\n",
    "When we use K-means method, one of the things we need to do is to choose the optimal number of clusters. We don't want to choose too few clusters, as they will group data with significant differences together; nor do we want to have to many clusters, as it will cause overfitting. To find the optimal number of clusters, we resort to elbow method. It involves estimating the model using various numbers of clusters and calculating the negative of the within-cluster sum of squares for each number of clusters chosen using the score method from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the optimal number of clusters for X_short\n",
    "number_clusters = range(1, 15)\n",
    "\n",
    "kmeans = [KMeans(n_clusters=i, max_iter = 600) for i in number_clusters]\n",
    "kmeans\n",
    "\n",
    "score = [kmeans[i].fit(X_short).score(X_short) for i in range(len(kmeans))]\n",
    "score\n",
    "\n",
    "plt.plot(number_clusters, score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### hierachical clustering 8 and 12 dandrogram top 50 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the optimal number of clusters for X_long\n",
    "number_clusters = range(1, 15)\n",
    "\n",
    "kmeans = [KMeans(n_clusters=i, max_iter = 600) for i in number_clusters]\n",
    "kmeans\n",
    "\n",
    "score = [kmeans[i].fit(X_long).score(X_long) for i in range(len(kmeans))]\n",
    "score\n",
    "\n",
    "plt.plot(number_clusters, score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()\n",
    "\n",
    "### hierachical clustering 8 dandrogram top 50 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "X1_pca = sklearn_pca.fit_transform(X1)\n",
    "kmeans = KMeans(n_clusters=3, max_iter=600, algorithm = 'auto')\n",
    "fitted = kmeans.fit(X1_pca)\n",
    "prediction = kmeans.predict(X1_pca)\n",
    "\n",
    "plt.scatter(X1_pca[:, 0], X1_pca[:, 1], c=predicted_values, s=50, cmap='viridis')\n",
    "\n",
    "centers = fitted.centroids\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pca = PCA(n_components = 2)\n",
    "X3_pca = sklearn_pca.fit_transform(X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing dimensionality reduction using LSA\n",
    "\n",
    "Vectorizer results are normalized, which makes KMeans behave as spherical k-means for better results. Since LSA/SVD results are not normazlied, we need to redo the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'Normalizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8b78e1652f57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for X1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSVD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_short\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'Normalizer'"
     ]
    }
   ],
   "source": [
    "# for X1\n",
    "SVD = TruncatedSVD(n_components = 10)\n",
    "normalizer = preprocessing.Normalizer(copy = False)\n",
    "lsa = make_pipeline(SVD, normalizer)\n",
    "X = lsa.fit_transform(X_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which component explains the variance the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0], SVD.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explained variance with different number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X1\n",
    "for i in range(1,15):\n",
    "    t0 = time()\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=i)\n",
    "    normalizer = preprocessing.Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "    X = lsa.fit_transform(X1)\n",
    "\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X2\n",
    "for i in range(1,15):\n",
    "    t0 = time()\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=i)\n",
    "    normalizer = preprocessing.Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "    X = lsa.fit_transform(X2)\n",
    "\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export TFIDF vectors to gensim and let it know the mapping of row index to term:\n",
    "- Convert sparse matrix of counts to a gensim corpus\n",
    "- Transpose it for gensim -> needs to be terms by docs instead of docs by terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_short\n",
    "tfidf_corpus1 = matutils.Sparse2Corpus(X_short.transpose())\n",
    "\n",
    "# Row indices\n",
    "id2word1 = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "\n",
    "id2word1 = corpora.Dictionary.from_corpus(tfidf_corpus1, \n",
    "                                         id2word=id2word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_long\n",
    "tfidf_corpus2 = matutils.Sparse2Corpus(X_long.transpose())\n",
    "\n",
    "# Row indices\n",
    "id2word2 = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "\n",
    "id2word2 = corpora.Dictionary.from_corpus(tfidf_corpus2, \n",
    "                                         id2word=id2word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA/LSI in gensim\n",
    "Build an LSI space from the input TFIDF matrix, mapping of row id to word, and num_topics.\n",
    "num_topics is the number of dimensions to reduce to after the SVD.\n",
    "Same as \"fit\" in sklearn, it primes an LSI space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('valu', 0.25102087459497263),\n",
       "   ('write', 0.21411702695161713),\n",
       "   ('school', 0.18425912813997317),\n",
       "   ('general', 0.1784510282713659),\n",
       "   ('job', 0.15958458789071867),\n",
       "   ('less', 0.15760089452374013),\n",
       "   ('month', 0.1462110779890985),\n",
       "   ('knowledg', 0.13985268341730112),\n",
       "   ('train', 0.13886525211057224),\n",
       "   ('lot', 0.1341174428143345),\n",
       "   ('peopl', 0.12817089713680382),\n",
       "   ('need', 0.12800908913101908),\n",
       "   ('manag', 0.12406546657881577),\n",
       "   ('though', 0.12315153143189651),\n",
       "   ('way', 0.11823783740421281)]),\n",
       " (1,\n",
       "  [('valu', -0.5521490603626135),\n",
       "   ('question', -0.26215653739111666),\n",
       "   ('read', -0.26032216832659927),\n",
       "   ('month', -0.250959929936329),\n",
       "   ('job', 0.246273485056497),\n",
       "   ('school', 0.18986565804830713),\n",
       "   ('scienc', 0.16106950166604941),\n",
       "   ('come', 0.13668739304605124),\n",
       "   ('ds', 0.136630066627096),\n",
       "   ('interview', 0.13276868357082838),\n",
       "   ('result', 0.1278853238355486),\n",
       "   ('math', 0.12119492672902045),\n",
       "   ('degre', 0.11485112055454096),\n",
       "   ('engin', 0.1133713466189721),\n",
       "   ('notebook', -0.11041578203391762)]),\n",
       " (2,\n",
       "  [('month', -0.507917263480754),\n",
       "   ('read', 0.443849224333338),\n",
       "   ('question', 0.4430273330011806),\n",
       "   ('consid', 0.17585635599461596),\n",
       "   ('pretti', -0.1585149292069612),\n",
       "   ('learn', 0.15343167146420902),\n",
       "   ('specif', 0.1413021800624411),\n",
       "   ('experi', -0.13838793422389448),\n",
       "   ('less', 0.13806666541402024),\n",
       "   ('valu', -0.12337490593809625),\n",
       "   ('two', -0.11624127543591875),\n",
       "   ('run', 0.11406732522116023),\n",
       "   ('project', 0.10220839183747349),\n",
       "   ('current', -0.09223806178413606),\n",
       "   ('open', 0.09096479938143567)]),\n",
       " (3,\n",
       "  [('month', 0.5690089042225515),\n",
       "   ('valu', -0.32071298291354733),\n",
       "   ('read', 0.27112275584702544),\n",
       "   ('question', 0.21279800390661147),\n",
       "   ('less', 0.20410577391281032),\n",
       "   ('stat', 0.17489944772129792),\n",
       "   ('write', -0.16093331051745272),\n",
       "   ('school', 0.14381121706550618),\n",
       "   ('pretti', 0.12788931774534515),\n",
       "   ('may', 0.12504062478983338),\n",
       "   ('lot', -0.12433907470823122),\n",
       "   ('notebook', -0.12191604427243577),\n",
       "   ('engin', 0.10468990024158754),\n",
       "   ('ml', -0.09761984937244243),\n",
       "   ('two', 0.09332189256436807)]),\n",
       " (4,\n",
       "  [('consid', -0.43471914179507987),\n",
       "   ('less', -0.3050718737744072),\n",
       "   ('read', 0.2726457757217453),\n",
       "   ('come', 0.23421624438551214),\n",
       "   ('job', 0.19685328006793032),\n",
       "   ('write', 0.191254751549871),\n",
       "   ('question', 0.18564726846251117),\n",
       "   ('may', -0.17998292489304515),\n",
       "   ('stat', -0.16473357207242648),\n",
       "   ('program', 0.14165371472527605),\n",
       "   ('scienc', 0.13637082711879703),\n",
       "   ('better', -0.13472999543289704),\n",
       "   ('valu', -0.1312515384317508),\n",
       "   ('school', -0.1259562971829348),\n",
       "   ('month', 0.12557886393903123)]),\n",
       " (5,\n",
       "  [('valu', -0.48918655674943473),\n",
       "   ('peopl', 0.21607566509869378),\n",
       "   ('job', -0.2159448238988607),\n",
       "   ('practic', 0.18090480825790592),\n",
       "   ('appli', 0.17645461942372317),\n",
       "   ('real', 0.15839619209967004),\n",
       "   ('math', -0.15615670290304665),\n",
       "   ('result', -0.13988670792525537),\n",
       "   ('expect', -0.13600185187780298),\n",
       "   ('depend', 0.1344421513292491),\n",
       "   ('degre', -0.12926084644478494),\n",
       "   ('engin', -0.12737687381904333),\n",
       "   ('manag', 0.12573228157991792),\n",
       "   ('knowledg', 0.12037162796015659),\n",
       "   ('project', -0.12010268905514954)])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for X1\n",
    "lsi = models.LsiModel(tfidf_corpus1, id2word=id2word1, num_topics=6)\n",
    "lsi.show_topics(300,15,formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('work', 0.22358254110002737),\n",
       "   ('us', 0.18381595324184039),\n",
       "   ('go', 0.1823912020032431),\n",
       "   ('role', 0.17292972509071147),\n",
       "   ('kind', 0.1660798838381102),\n",
       "   ('level', 0.15308706323808907),\n",
       "   ('part', 0.14903378910913048),\n",
       "   ('model', 0.14866652607769593),\n",
       "   ('compani', 0.1477508012570105),\n",
       "   ('time', 0.13678436164495184),\n",
       "   ('need', 0.13301605616898882),\n",
       "   ('manag', 0.12467245860014585),\n",
       "   ('think', 0.12423360397779418),\n",
       "   ('languag', 0.12002178897454549),\n",
       "   ('hard', 0.11761683530067796)]),\n",
       " (1,\n",
       "  [('model', 0.43024601920431343),\n",
       "   ('us', 0.3506313894293377),\n",
       "   ('kind', -0.27573438079847096),\n",
       "   ('role', -0.23365135966037462),\n",
       "   ('field', 0.21492158034686737),\n",
       "   ('compani', -0.16684885880804964),\n",
       "   ('posit', 0.15321526268319383),\n",
       "   ('ds', -0.13939669258532683),\n",
       "   ('problem', -0.13517227413299335),\n",
       "   ('dataset', 0.1314939463791949),\n",
       "   ('degre', -0.1305545193792542),\n",
       "   ('run', -0.12979360364753068),\n",
       "   ('put', 0.1287216897953656),\n",
       "   ('research', -0.1255924611887838),\n",
       "   ('train', 0.11404377125452703)]),\n",
       " (2,\n",
       "  [('program', 0.3721833327342172),\n",
       "   ('put', 0.3709436803345608),\n",
       "   ('problem', 0.2872967590747771),\n",
       "   ('level', 0.25324260739839993),\n",
       "   ('compani', -0.2217934138497132),\n",
       "   ('role', 0.19463636754928507),\n",
       "   ('less', 0.18320913477524664),\n",
       "   ('market', -0.16113094802244685),\n",
       "   ('cours', 0.15771365865597453),\n",
       "   ('math', 0.14931347205799114),\n",
       "   ('talk', -0.14899582280521045),\n",
       "   ('sql', 0.14338829369433928),\n",
       "   ('us', 0.13932690929049452),\n",
       "   ('master', 0.1385554815529549),\n",
       "   ('work', -0.13147075472339886)]),\n",
       " (3,\n",
       "  [('model', -0.4787396740967152),\n",
       "   ('role', -0.31806644230642284),\n",
       "   ('program', 0.27577819504605333),\n",
       "   ('put', 0.24530825269704837),\n",
       "   ('enough', -0.17820922678994344),\n",
       "   ('posit', -0.17212902969556468),\n",
       "   ('run', -0.16524720827866474),\n",
       "   ('job', 0.14551036217511235),\n",
       "   ('code', 0.13560573242895738),\n",
       "   ('field', -0.13422187693392582),\n",
       "   ('problem', -0.13054894137106765),\n",
       "   ('sql', -0.12703598470935726),\n",
       "   ('less', 0.12700687585369297),\n",
       "   ('math', -0.11701142933886469),\n",
       "   ('first', -0.11351321973052159)]),\n",
       " (4,\n",
       "  [('talk', 0.30010387785157655),\n",
       "   ('put', 0.2624158779247698),\n",
       "   ('compani', 0.254118196763662),\n",
       "   ('program', 0.2528950998287767),\n",
       "   ('run', 0.19292758945696684),\n",
       "   ('enough', 0.18225896401931416),\n",
       "   ('level', -0.17517056650845814),\n",
       "   ('cours', -0.16773500255583298),\n",
       "   ('analyst', 0.1603066849118857),\n",
       "   ('go', -0.1581528299434365),\n",
       "   ('research', 0.14745838226509228),\n",
       "   ('build', 0.14588771740167877),\n",
       "   ('field', -0.14071463197329964),\n",
       "   ('tri', -0.13581189601860133),\n",
       "   ('expect', 0.1316705468597616)]),\n",
       " (5,\n",
       "  [('job', 0.39755484881005426),\n",
       "   ('project', 0.26370228728988243),\n",
       "   ('code', -0.2614955277142584),\n",
       "   ('process', -0.20649146152571832),\n",
       "   ('predict', 0.20635467122268633),\n",
       "   ('talk', -0.19945119717270596),\n",
       "   ('work', -0.19794371313861917),\n",
       "   ('model', 0.17708120889190762),\n",
       "   ('field', -0.16609972740845386),\n",
       "   ('around', 0.16378969738210025),\n",
       "   ('languag', 0.15865335139528638),\n",
       "   ('program', 0.1508748235156408),\n",
       "   ('put', 0.14691018688480453),\n",
       "   ('idea', 0.13899123125102023),\n",
       "   ('sinc', 0.129778948970656)])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for X2\n",
    "lsi = models.LsiModel(tfidf_corpus2, id2word=id2word2, num_topics=6)\n",
    "lsi.show_topics(300,15,formatted=False)\n",
    "\n",
    "#### DISTANCE METRIC. Intre vs Inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project the tfidf vectors onto the first N principal components. Significantly fewer features than the original tfidf vector, but they are stronger features, and the accuracy is higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'Normalizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f5d53c927f7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for X1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvd_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlsa_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfeat_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'Normalizer'"
     ]
    }
   ],
   "source": [
    "# for X1\n",
    "svd_test = TruncatedSVD(10)\n",
    "lsa_test = make_pipeline(svd_test, preprocessing.Normalizer(copy=False))\n",
    "feat_names = vectorizer.get_feature_names()\n",
    "\n",
    "X_train_lsa = lsa_test.fit_transform(X_short)\n",
    "\n",
    "# The SVD matrix will have one row per component, and one column per feature\n",
    "# of the original data.\n",
    "\n",
    "for component_num in range(0, 5):\n",
    "\n",
    "    comp = svd_test.components_[component_num]\n",
    "    \n",
    "    # Sort the weights in the first component, and get the indeces.\n",
    "    indeces = np.argsort(comp).tolist()\n",
    "    \n",
    "    # Get largest weights first.\n",
    "    indeces.reverse()\n",
    "    \n",
    "    # Get top 10 terms with highest weight in this component.        \n",
    "    terms = [feat_names[weightIndex] for weightIndex in indeces[0:10]]    \n",
    "    weights = [comp[weightIndex] for weightIndex in indeces[0:10]]    \n",
    "   \n",
    "    # Plot terms and weights as a horizontal bar graph.    \n",
    "    # The horizontal bar graph displays the first item on the bottom; reverse\n",
    "    # the order of the terms so the biggest one is on top.\n",
    "    terms.reverse()\n",
    "    weights.reverse()\n",
    "    positions = range(10)    # the bar centers on the y axis\n",
    "    \n",
    "    plt.figure(component_num)\n",
    "    plt.barh(positions, weights, align='center')\n",
    "    plt.yticks(positions, terms)\n",
    "    plt.xlabel('Weight')\n",
    "    plt.title('Strongest terms for component %d' % (component_num))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X2\n",
    "svd_test = TruncatedSVD(10)\n",
    "lsa_test = make_pipeline(svd_test, preprocessing.Normalizer(copy=False))\n",
    "feat_names = vectorizer2.get_feature_names()\n",
    "\n",
    "X_train_lsa = lsa_test.fit_transform(X_long)\n",
    "\n",
    "# The SVD matrix will have one row per component, and one column per feature\n",
    "# of the original data.\n",
    "\n",
    "for component_num in range(0, 5):\n",
    "\n",
    "    comp = svd_test.components_[component_num]\n",
    "    \n",
    "    # Sort the weights in the first component, and get the indeces.\n",
    "    indeces = np.argsort(comp).tolist()\n",
    "    \n",
    "    # Get largest weights first.\n",
    "    indeces.reverse()\n",
    "    \n",
    "    # Get top 10 terms with highest weight in this component.        \n",
    "    terms = [feat_names[weightIndex] for weightIndex in indeces[0:10]]    \n",
    "    weights = [comp[weightIndex] for weightIndex in indeces[0:10]]    \n",
    "   \n",
    "    # Plot terms and weights as a horizontal bar graph.    \n",
    "    # The horizontal bar graph displays the first item on the bottom; reverse\n",
    "    # the order of the terms so the biggest one is on top.\n",
    "    terms.reverse()\n",
    "    weights.reverse()\n",
    "    positions = range(10)    # the bar centers on the y axis\n",
    "    \n",
    "    plt.figure(component_num)\n",
    "    plt.barh(positions, weights, align='center')\n",
    "    plt.yticks(positions, terms)\n",
    "    plt.xlabel('Weight')\n",
    "    plt.title('Strongest terms for component %d' % (component_num))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "### top x bigrams\n",
    "\n",
    "### filter samples by the number of tokens. how many tokens is total after. distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# SVD represent documents and terms in vectors \n",
    "svd_model = TruncatedSVD(n_components=6, algorithm='randomized', n_iter=100, random_state=122)\n",
    "\n",
    "svd_model.fit(X_short)\n",
    "\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "('valu', 0.2510219643418864)\n",
      " \n",
      "('write', 0.2141194641749164)\n",
      " \n",
      "('school', 0.1842608626170733)\n",
      " \n",
      "('general', 0.17845745577294306)\n",
      " \n",
      "('job', 0.15958326983291687)\n",
      " \n",
      "('less', 0.15760514390115193)\n",
      " \n",
      "('month', 0.14621205425967185)\n",
      " \n",
      "Topic 1: \n",
      "('valu', 0.5522456810880885)\n",
      " \n",
      "('question', 0.2618478287120751)\n",
      " \n",
      "('read', 0.2605043221169908)\n",
      " \n",
      "('month', 0.25100284581773796)\n",
      " \n",
      "('notebook', 0.11054100667741278)\n",
      " \n",
      "('chang', 0.11015997811252881)\n",
      " \n",
      "('open', 0.10533410100158537)\n",
      " \n",
      "Topic 2: \n",
      "('read', 0.4437968139190086)\n",
      " \n",
      "('question', 0.44270989545906875)\n",
      " \n",
      "('consid', 0.17620140471812795)\n",
      " \n",
      "('learn', 0.15427695382610698)\n",
      " \n",
      "('specif', 0.14102695683341585)\n",
      " \n",
      "('less', 0.1391652916503286)\n",
      " \n",
      "('run', 0.11455534635941948)\n",
      " \n",
      "Topic 3: \n",
      "('month', 0.5695743597238199)\n",
      " \n",
      "('read', 0.2710868860616366)\n",
      " \n",
      "('question', 0.21150616893221483)\n",
      " \n",
      "('less', 0.2062637066854733)\n",
      " \n",
      "('stat', 0.1755697640154135)\n",
      " \n",
      "('school', 0.14168890570351894)\n",
      " \n",
      "('pretti', 0.1289933009557725)\n",
      " \n",
      "Topic 4: \n",
      "('consid', 0.4353643485213028)\n",
      " \n",
      "('less', 0.3061449695615609)\n",
      " \n",
      "('may', 0.18020518749962655)\n",
      " \n",
      "('stat', 0.16357400506312578)\n",
      " \n",
      "('better', 0.13312838333723995)\n",
      " \n",
      "('valu', 0.13053978219306064)\n",
      " \n",
      "('school', 0.12703996720502814)\n",
      " \n",
      "Topic 5: \n",
      "('valu', 0.4900628248297777)\n",
      " \n",
      "('job', 0.21534934136567296)\n",
      " \n",
      "('math', 0.15670580345421536)\n",
      " \n",
      "('result', 0.13763789312859867)\n",
      " \n",
      "('expect', 0.13628752219071558)\n",
      " \n",
      "('degre', 0.13197464013866184)\n",
      " \n",
      "('engin', 0.12750971340416345)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(svd_model.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        #print(t[0])\n",
    "        print(t)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import umap\n",
    "import umap.umap_ as umap\n",
    "\n",
    "X_topics = svd_model.fit_transform(X1)\n",
    "embedding = umap.UMAP(n_neighbors=150, min_dist=0.5, random_state=12).fit_transform(X_topics)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], \n",
    "#c = dataset.target,\n",
    "s = 10, # size\n",
    "edgecolor='none'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### after token, stem, do a counter vectorizer or sum the tokens for each row. what's the length of the row. take a look at the distribution. plot. think about the weighting. \n",
    "### we want to remove the outlier counts. a normalized length for each comment. remove super short/long comments. it will add some bias. \n",
    "### medium comment/short comment/long comment similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('machine', 'learning') 374\n",
      "('r', 'python') 129\n",
      "('make', 'sure') 125\n",
      "('deep', 'learning') 119\n",
      "('software', 'engineering') 118\n",
      "('python', 'r') 109\n",
      "('computer', 'science') 107\n",
      "('entry', 'level') 97\n",
      "('can', 'not') 95\n",
      "('years', 'ago') 88\n",
      "('get', 'job') 85\n",
      "('linear', 'regression') 81\n",
      "('use', 'python') 78\n",
      "('years', 'experience') 76\n",
      "('5', 'years') 73\n",
      "('pretty', 'much') 70\n",
      "('10', 'years') 69\n",
      "('lot', 'people') 68\n",
      "('open', 'source') 68\n",
      "('domain', 'knowledge') 68\n",
      "('need', 'know') 67\n",
      "('linear', 'algebra') 67\n",
      "('thanks', 'sharing') 66\n",
      "('use', 'r') 62\n",
      "('work', 'experience') 62\n",
      "('time', 'series') 61\n",
      "('real', 'world') 60\n",
      "('2', 'years') 59\n",
      "('make', 'sense') 58\n",
      "('hiring', 'manager') 58\n",
      "('masters', 'degree') 57\n",
      "('web', 'scraping') 56\n",
      "('first', 'job') 55\n",
      "('gon', 'na') 55\n",
      "('logistic', 'regression') 50\n",
      "('much', 'better') 50\n",
      "('full', 'time') 49\n",
      "('problem', 'solving') 49\n",
      "('grad', 'school') 49\n",
      "('3', 'years') 48\n",
      "('software', 'engineer') 48\n",
      "('go', 'back') 48\n",
      "('jupyter', 'notebook') 47\n",
      "('random', 'forest') 47\n",
      "('software', 'engineers') 47\n",
      "('feature', 'engineering') 47\n",
      "('soft', 'skills') 45\n",
      "('job', 'market') 45\n",
      "('best', 'way') 45\n",
      "('doesnt', 'matter') 45\n",
      "('masters', 'science') 45\n",
      "('6', 'months') 44\n",
      "('neural', 'networks') 43\n",
      "('programming', 'language') 43\n",
      "('much', 'easier') 43\n",
      "('little', 'bit') 43\n",
      "('makes', 'sense') 42\n",
      "('science', 'job') 42\n",
      "('using', 'python') 41\n",
      "('want', 'work') 41\n",
      "('someone', 'else') 41\n",
      "('science', 'team') 41\n",
      "('want', 'get') 40\n",
      "('business', 'analytics') 40\n",
      "('python', 'sql') 39\n",
      "('every', 'day') 39\n",
      "('high', 'level') 39\n",
      "('end', 'day') 39\n",
      "('spend', 'time') 39\n",
      "('technical', 'skills') 39\n",
      "('need', 'learn') 39\n",
      "('last', 'year') 38\n",
      "('trying', 'get') 38\n",
      "('science', 'jobs') 38\n",
      "('jupyter', 'notebooks') 38\n",
      "('tech', 'companies') 37\n",
      "('let', 'know') 36\n",
      "('people', 'know') 36\n",
      "('hiring', 'managers') 36\n",
      "('didnt', 'know') 35\n",
      "('doesnt', 'mean') 35\n",
      "('want', 'know') 35\n",
      "('4', 'years') 34\n",
      "('long', 'time') 34\n",
      "('solve', 'problem') 34\n",
      "('youve', 'got') 34\n",
      "('software', 'development') 34\n",
      "('much', 'time') 33\n",
      "('learn', 'python') 33\n",
      "('learn', 'new') 33\n",
      "('social', 'media') 33\n",
      "('high', 'school') 33\n",
      "('personal', 'projects') 32\n",
      "('ask', 'questions') 32\n",
      "('using', 'r') 32\n",
      "('science', 'career') 32\n",
      "('new', 'job') 31\n",
      "('pandas', 'numpy') 31\n",
      "('solve', 'problems') 31\n",
      "('part', 'time') 31\n",
      "('want', 'use') 31\n",
      "('everything', 'else') 31\n",
      "('power', 'bi') 31\n",
      "('get', 'paid') 31\n",
      "('climate', 'change') 31\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "stop_words = nltk_stop_words + more_stop_words\n",
    "comments_raw['COMMENTS'] = comments_raw['COMMENTS'].map(lambda text: \" \".join(word for word in text.split() if word not in stop_words))\n",
    "text = ' '.join(comments_raw['COMMENTS'])\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(word_tokenize(text))\n",
    "    \n",
    "for k,v in sorted(finder.ngram_fd.items(), key=lambda item: item[1], reverse=True):\n",
    "    if v > 30:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('machine', 'learning') 155\n",
      "('thanks', 'sharing') 65\n",
      "('r', 'python') 53\n",
      "('deep', 'learning') 52\n",
      "('python', 'r') 51\n",
      "('entry', 'level') 50\n",
      "('software', 'engineering') 49\n",
      "('can', 'not') 42\n",
      "('gon', 'na') 39\n",
      "('linear', 'algebra') 39\n",
      "('years', 'ago') 38\n",
      "('time', 'series') 38\n",
      "('linear', 'regression') 36\n",
      "('open', 'source') 35\n",
      "('get', 'job') 34\n",
      "('pretty', 'much') 34\n",
      "('years', 'experience') 33\n",
      "('masters', 'degree') 31\n",
      "('5', 'years') 30\n",
      "('logistic', 'regression') 30\n",
      "('need', 'know') 29\n",
      "('jupyter', 'notebook') 29\n",
      "('computer', 'science') 29\n",
      "('real', 'world') 29\n",
      "('use', 'python') 28\n",
      "('make', 'sure') 28\n",
      "('work', 'experience') 27\n",
      "('lot', 'people') 27\n",
      "('jupyter', 'notebooks') 27\n",
      "('much', 'better') 26\n",
      "('software', 'engineer') 26\n",
      "('first', 'job') 26\n",
      "('use', 'r') 25\n",
      "('job', 'market') 25\n",
      "('10', 'years') 24\n",
      "('3', 'years') 23\n",
      "('soft', 'skills') 23\n",
      "('open', 'office') 23\n",
      "('2', 'years') 22\n",
      "('didnt', 'know') 22\n",
      "('domain', 'knowledge') 22\n",
      "('learning', 'science') 21\n",
      "('programming', 'language') 21\n"
     ]
    }
   ],
   "source": [
    "comments_short['COMMENTS'] = comments_short['COMMENTS'].map(lambda text: \" \".join(word for word in text.split() if word not in stop_words))\n",
    "text = ' '.join(comments_short['COMMENTS'])\n",
    "\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(word_tokenize(text))\n",
    "    \n",
    "for k,v in sorted(finder.ngram_fd.items(), key=lambda item: item[1], reverse=True):\n",
    "    if v > 20:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('machine', 'learning') 217\n",
      "('make', 'sure') 97\n",
      "('computer', 'science') 77\n",
      "('r', 'python') 75\n",
      "('software', 'engineering') 68\n",
      "('deep', 'learning') 67\n",
      "('python', 'r') 59\n",
      "('can', 'not') 53\n",
      "('get', 'job') 51\n",
      "('use', 'python') 50\n",
      "('years', 'ago') 49\n",
      "('entry', 'level') 47\n",
      "('domain', 'knowledge') 46\n",
      "('10', 'years') 45\n",
      "('linear', 'regression') 45\n",
      "('5', 'years') 43\n",
      "('years', 'experience') 43\n",
      "('web', 'scraping') 42\n",
      "('lot', 'people') 41\n",
      "('hiring', 'manager') 40\n",
      "('need', 'know') 38\n",
      "('make', 'sense') 38\n",
      "('use', 'r') 37\n",
      "('2', 'years') 37\n",
      "('random', 'forest') 37\n",
      "('pretty', 'much') 36\n",
      "('problem', 'solving') 34\n",
      "('work', 'experience') 34\n",
      "('go', 'back') 33\n",
      "('open', 'source') 33\n",
      "('grad', 'school') 33\n",
      "('software', 'engineers') 32\n",
      "('6', 'months') 32\n",
      "('feature', 'engineering') 32\n",
      "('little', 'bit') 31\n",
      "('doesnt', 'matter') 31\n",
      "('real', 'world') 31\n",
      "('masters', 'science') 30\n",
      "('neural', 'networks') 30\n",
      "('much', 'easier') 30\n",
      "('first', 'job') 29\n",
      "('pandas', 'numpy') 29\n",
      "('high', 'level') 29\n",
      "('linear', 'algebra') 28\n",
      "('end', 'day') 28\n",
      "('full', 'time') 28\n",
      "('science', 'job') 27\n",
      "('every', 'day') 27\n",
      "('best', 'way') 27\n",
      "('want', 'know') 27\n",
      "('someone', 'else') 26\n",
      "('masters', 'degree') 26\n",
      "('spend', 'time') 26\n",
      "('decision', 'trees') 26\n",
      "('science', 'team') 26\n",
      "('hiring', 'managers') 26\n",
      "('science', 'jobs') 25\n",
      "('3', 'years') 25\n",
      "('makes', 'sense') 25\n",
      "('ask', 'questions') 24\n",
      "('much', 'better') 24\n",
      "('technical', 'skills') 24\n",
      "('need', 'learn') 24\n",
      "('9th', 'circuit') 24\n",
      "('circuit', 'court') 24\n",
      "('court', 'appeals') 24\n",
      "('circuit', 'courts') 24\n",
      "('python', 'sql') 23\n",
      "('current', 'job') 23\n",
      "('amount', 'time') 23\n",
      "('solve', 'problem') 23\n",
      "('time', 'series') 23\n",
      "('recommendation', 'system') 23\n",
      "('find', 'job') 22\n",
      "('soft', 'skills') 22\n",
      "('last', 'year') 22\n",
      "('everything', 'else') 22\n",
      "('software', 'engineer') 22\n",
      "('want', 'work') 22\n",
      "('business', 'analytics') 22\n",
      "('write', 'code') 22\n",
      "('programming', 'language') 22\n",
      "('libraries', 'use') 22\n",
      "('steps', 'take') 22\n",
      "('climate', 'change') 22\n",
      "('think', 'people') 21\n",
      "('learn', 'new') 21\n",
      "('solve', 'problems') 21\n",
      "('using', 'python') 21\n",
      "('people', 'know') 21\n",
      "('want', 'get') 21\n",
      "('doesnt', 'mean') 21\n",
      "('software', 'development') 21\n",
      "('answer', 'question') 21\n",
      "('high', 'school') 21\n",
      "('learning', 'algos') 21\n",
      "('use', 'linear') 21\n"
     ]
    }
   ],
   "source": [
    "comments_long['COMMENTS'] = comments_long['COMMENTS'].map(lambda text: \" \".join(word for word in text.split() if word not in stop_words))\n",
    "text = ' '.join(comments_long['COMMENTS'])\n",
    "\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(word_tokenize(text))\n",
    "    \n",
    "for k,v in sorted(finder.ngram_fd.items(), key=lambda item: item[1], reverse=True):\n",
    "    if v > 20:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>bootcamp</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Frequency\n",
       "793  bootcamp         72"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist # this also uses Counter. \n",
    "\n",
    "\n",
    "unigram_list = FreqDist(' '.join(comments_raw['COMMENTS']).split()).most_common(1000)\n",
    "#' '.join(ds_comments_raw['Comments']).split()\n",
    "\n",
    "unigram_df = pd.DataFrame(unigram_list, columns=[\"Word\", \"Frequency\"])\n",
    "unigram_df[unigram_df['Word'] == 'bootcamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>know</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>python</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>people</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>job</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>time</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>r</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>think</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>need</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>want</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>learning</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>much</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lot</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>make</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ds</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>experience</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>well</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Frequency\n",
       "0      science       1056\n",
       "1         work        884\n",
       "2          get        809\n",
       "3          use        711\n",
       "4         know        676\n",
       "5       python        668\n",
       "6       people        665\n",
       "7          job        662\n",
       "8         time        614\n",
       "9            r        575\n",
       "10       think        570\n",
       "11        need        497\n",
       "12        want        485\n",
       "13    learning        484\n",
       "14        much        463\n",
       "15         lot        451\n",
       "16        make        408\n",
       "17          ds        401\n",
       "18  experience        399\n",
       "19        well        387"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist # this also uses Counter. \n",
    "\n",
    "\n",
    "unigram_list = FreqDist(' '.join(comments_short['COMMENTS']).split()).most_common(100)\n",
    "#' '.join(ds_comments_raw['Comments']).split()\n",
    "\n",
    "unigram_df = pd.DataFrame(unigram_list, columns=[\"Word\", \"Frequency\"])\n",
    "unigram_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>work</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>science</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>job</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>think</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>need</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>use</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>python</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>know</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>want</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>r</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lot</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>make</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>much</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>learning</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>experience</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>things</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ds</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Frequency\n",
       "0         work       1291\n",
       "1      science       1222\n",
       "2          get       1144\n",
       "3       people       1050\n",
       "4          job        914\n",
       "5         time        908\n",
       "6        think        824\n",
       "7         need        792\n",
       "8          use        779\n",
       "9       python        776\n",
       "10        know        739\n",
       "11        want        685\n",
       "12           r        643\n",
       "13         lot        621\n",
       "14        make        609\n",
       "15        much        589\n",
       "16    learning        581\n",
       "17  experience        577\n",
       "18      things        553\n",
       "19          ds        542"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist # this also uses Counter. \n",
    "\n",
    "\n",
    "unigram_list = FreqDist(' '.join(comments_long['COMMENTS']).split()).most_common(100)\n",
    "#' '.join(ds_comments_raw['Comments']).split()\n",
    "\n",
    "unigram_df = pd.DataFrame(unigram_list, columns=[\"Word\", \"Frequency\"])\n",
    "unigram_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12/04/20\n",
    "Take a look at the bootcamp comments for the last six months (check the data source)| or 3 months\n",
    "Generate a report for marketing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'bootcamp' ' '.join(comments_raw['COMMENTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
